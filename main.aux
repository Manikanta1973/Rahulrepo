\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Declaration of Authorship}{i}{dummy.1}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Abstract}{ii}{dummy.2}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iii}{dummy.3}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Contents}{iv}{dummy.4}}
\gdef \LT@i {\LT@entry 
    {1}{61.20627pt}\LT@entry 
    {1}{240.64961pt}}
\@writefile{toc}{\contentsline {chapter}{Abbreviations}{viii}{dummy.6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter1}{{1}{1}{Introduction}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Multimodal Representation Learning}{1}{section.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The Stirling engine from my desk.\relax }}{2}{figure.caption.12}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:stirling}{{1.1}{2}{The Stirling engine from my desk.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Motivation}{2}{section.11}}
\citation{smith2008infants}
\citation{yurovsky2013statistical}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces The bi-directional nature of language learning.\relax }}{3}{figure.caption.13}}
\newlabel{fig:bi_ll}{{1.2}{3}{The bi-directional nature of language learning.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Associations among words and objects across multiple ambiguous scenes allow learners to find the proper mapping of words: ''Circle", ''Square", ''Green" and ''Blue" to objects and colours: \textit  {Circle}, \textit  {Square}, \textit  {Green} \textit  {Blue}\relax }}{3}{figure.caption.14}}
\newlabel{fig:cross_sitch}{{1.3}{3}{Associations among words and objects across multiple ambiguous scenes allow learners to find the proper mapping of words: ''Circle", ''Square", ''Green" and ''Blue" to objects and colours: \textit {Circle}, \textit {Square}, \textit {Green} \textit {Blue}\relax }{figure.caption.14}{}}
\@writefile{tdo}{\contentsline {todo}{Figure: Placeholder}{4}{figure.caption.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Images generated from labellings of natural images (left) and labellings generated from natural images (right)\relax }}{4}{figure.caption.15}}
\newlabel{fig:mrl_teaser}{{1.4}{4}{Images generated from labellings of natural images (left) and labellings generated from natural images (right)\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{chapter.16}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter2}{{2}{5}{Background}{chapter.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{5}{section.17}}
\newlabel{Lit:Intro}{{2.1}{5}{Introduction}{section.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}What are Artifical Neural Networks good at?}{5}{section.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Classification}{6}{subsection.19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Generation}{6}{subsection.20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Reinforcement Learning}{6}{subsection.21}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}What are Artificial Neural Networks bad at?}{6}{section.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}data ineffciency}{6}{subsection.23}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}How to Get Off the Symbol Grounding Merry-Go-Round}{6}{section.24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}What is symbol grounding?}{6}{subsection.25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}How do humans do it?}{6}{subsection.26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}How do machines do it?}{6}{subsection.27}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Why brains are better}{6}{section.28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Embodiment}{6}{subsection.29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1.1}Sensory Redundancy}{6}{subsubsection.30}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1.2}Biological Filters}{6}{subsubsection.31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Development}{7}{subsection.32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2.1}Biological Filters, again}{7}{subsubsection.33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Pulling yourself up by the bootstraps}{7}{subsection.34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Machine Equivelancy}{7}{subsection.35}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.4.1}How do we simulate Embodiment for ANNs?}{7}{subsubsection.36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.4.2}How do we simulate Development for ANNs?}{7}{subsubsection.37}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Where do we go from here?}{7}{section.38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Robot bodies}{7}{subsection.39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}multimodality}{7}{subsection.40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}transfer learning}{7}{subsection.41}}
\citation{rosenblatt1958perceptron}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}A Primer on Artifical Neural Networks}{8}{chapter.42}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter3}{{3}{8}{A Primer on Artifical Neural Networks}{chapter.42}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{8}{section.43}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Perceptrons}{8}{section.44}}
\newlabel{sec:percep}{{3.2}{8}{Perceptrons}{section.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}What is a Perceptron}{8}{subsection.45}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces A perceptron with three binary inputs, $x_0, x_1, x_2$.\relax }}{9}{figure.caption.46}}
\newlabel{fig:perceptron}{{3.1}{9}{A perceptron with three binary inputs, $x_0, x_1, x_2$.\relax }{figure.caption.46}{}}
\newlabel{eqn:percep}{{3.1}{9}{What is a Perceptron}{equation.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A multi-layer perceptron consisting of three perceptrons arranged in two layers, with three binary inputs, $x_0, x_1, x_2$.\relax }}{10}{figure.caption.49}}
\newlabel{fig:mlp}{{3.2}{10}{A multi-layer perceptron consisting of three perceptrons arranged in two layers, with three binary inputs, $x_0, x_1, x_2$.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Multi-Layer Perceptron}{10}{subsection.48}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Activation Functions}{10}{section.50}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Visualisation of the perceptron activation function.\relax }}{11}{figure.caption.51}}
\newlabel{fig:activation_percep}{{3.3}{11}{Visualisation of the perceptron activation function.\relax }{figure.caption.51}{}}
\newlabel{eqn:proport}{{3.2}{11}{Activation Functions}{equation.52}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Sigmoid Neurons}{11}{subsection.53}}
\newlabel{eqn:sig}{{3.3}{11}{Sigmoid Neurons}{equation.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Visualisation of the sigmoid activation function.\relax }}{12}{figure.caption.56}}
\newlabel{fig:activation_sigmoid}{{3.4}{12}{Visualisation of the sigmoid activation function.\relax }{figure.caption.56}{}}
\newlabel{eqn:z_act}{{3.4}{12}{Sigmoid Neurons}{equation.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1.1}Other activation functions}{12}{subsubsection.57}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Visualisation of the hyperbolic tangent activation function.\relax }}{13}{figure.caption.58}}
\newlabel{fig:activation_tanh}{{3.5}{13}{Visualisation of the hyperbolic tangent activation function.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Visualisation of the rectified linear unit activation function.\relax }}{13}{figure.caption.59}}
\newlabel{fig:activation_relu}{{3.6}{13}{Visualisation of the rectified linear unit activation function.\relax }{figure.caption.59}{}}
\citation{lecun1998mnist}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Learning Algorithms}{14}{section.61}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Types of Training}{14}{subsection.63}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Cost functions: How wrong am I?}{15}{subsection.64}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2.1}Mean Squared Error}{15}{subsubsection.65}}
\newlabel{eqn:mse}{{3.5}{15}{Mean Squared Error}{equation.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2.2}Cross-Entropy}{15}{subsubsection.67}}
\newlabel{eqn:xntrpy}{{3.6}{16}{Cross-Entropy}{equation.68}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2.3}Kullback-Leibler Divergence}{16}{subsubsection.69}}
\newlabel{eqn:kld}{{3.7}{16}{Kullback-Leibler Divergence}{equation.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces The cost landscape of a bivariate function\relax }}{17}{figure.caption.72}}
\newlabel{fig:costscape}{{3.7}{17}{The cost landscape of a bivariate function\relax }{figure.caption.72}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Gradient Descent}{17}{subsection.71}}
\newlabel{eqn:cost_bivar}{{3.8}{18}{Gradient Descent}{equation.73}{}}
\newlabel{eqn:delta_C}{{3.9}{18}{Gradient Descent}{equation.74}{}}
\newlabel{eqn:nabla_c}{{3.10}{18}{Gradient Descent}{equation.75}{}}
\newlabel{eqn:delta_c_sub}{{3.11}{18}{Gradient Descent}{equation.76}{}}
\newlabel{eqn:delta_w_eta}{{3.12}{18}{Gradient Descent}{equation.77}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Backpropagation}{19}{subsection.79}}
\newlabel{eqn:BP1}{{3.13}{19}{Backpropagation}{equation.80}{}}
\newlabel{eqn:BP2}{{3.14}{19}{Backpropagation}{equation.81}{}}
\newlabel{eqn:BP3}{{3.16}{19}{Backpropagation}{equation.84}{}}
\newlabel{eqn:hada}{{3.15}{19}{}{equation.83}{}}
\newlabel{eqn:BP4}{{3.17}{20}{Backpropagation}{equation.85}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Extensions and Improvements}{20}{subsection.86}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.5.1}Learning Rate Schedule}{20}{subsubsection.87}}
\newlabel{sec:lr_sch}{{3.4.5.1}{20}{Learning Rate Schedule}{subsubsection.87}{}}
\citation{kingma2014adam}
\citation{zeiler2012adadelta}
\citation{senior2013empirical}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Visualisation of cost minimisation in two dimensions for different learning rate schedules. Blue: decreaseing learning rate, Red: large fixed learning rate.\relax }}{21}{figure.caption.88}}
\newlabel{fig:lr_schedule}{{3.8}{21}{Visualisation of cost minimisation in two dimensions for different learning rate schedules. Blue: decreaseing learning rate, Red: large fixed learning rate.\relax }{figure.caption.88}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Visualisation of the cost (black), its first derivative (blue) and second derivative (red).\relax }}{22}{figure.caption.89}}
\newlabel{fig:2ndordr}{{3.9}{22}{Visualisation of the cost (black), its first derivative (blue) and second derivative (red).\relax }{figure.caption.89}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces A Long Short-Term Memory Unit\relax }}{23}{figure.caption.99}}
\newlabel{fig:lstm}{{3.10}{23}{A Long Short-Term Memory Unit\relax }{figure.caption.99}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Convolutional Neural Networks}{23}{section.90}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}What is Convolution?}{23}{subsection.91}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1.1}Kernels}{23}{subsubsection.92}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1.2}Strides}{23}{subsubsection.93}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1.3}Dilations}{23}{subsubsection.94}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Transposed Convolutions}{23}{subsection.95}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Recurrent Neural Networks}{23}{section.96}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Vanilla RNN}{23}{subsection.97}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Gated RNN}{23}{subsection.98}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Summary}{23}{section.101}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces A Gated Recurrent Unit\relax }}{24}{figure.caption.100}}
\newlabel{fig:gru}{{3.11}{24}{A Gated Recurrent Unit\relax }{figure.caption.100}{}}
\citation{barsalou2008grounded}
\citation{mcgurk1976hearing}
\citation{ma2009lip}
\citation{ma2009lip,samuel1997lexical}
\citation{ngiam2011multimodal}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Sensory Redundancy: Are two heads better than one?}{25}{chapter.102}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter4}{{4}{25}{Sensory Redundancy: Are two heads better than one?}{chapter.102}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Why have one sensor when two are better?}{25}{section.103}}
\citation{hammami2009tree,hammami2010improved}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Generating images from natural language}{26}{section.104}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Aims}{26}{subsection.105}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}UCU Arabic Spoken Digits and MNIST}{26}{subsection.106}}
\newlabel{sec:UCU}{{4.2.2}{26}{UCU Arabic Spoken Digits and MNIST}{subsection.106}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2.1}UCU Arabic Spoken Digits}{26}{subsubsection.107}}
\citation{lecun1998mnist}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Mean number of samples for each digit in the UCU Arabic Spoken Digits Dataset. Red bars show the standard devaition in length for each each digit.\relax }}{27}{figure.caption.109}}
\newlabel{fig:ucu_dig_length}{{4.1}{27}{Mean number of samples for each digit in the UCU Arabic Spoken Digits Dataset. Red bars show the standard devaition in length for each each digit.\relax }{figure.caption.109}{}}
\citation{barsalou2008grounded}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Mean length and standard deviation of digits in the UCU dataset.\relax }}{28}{table.caption.110}}
\newlabel{tab:UCU_sampLen}{{4.1}{28}{Mean length and standard deviation of digits in the UCU dataset.\relax }{table.caption.110}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2.2}MNIST Handwritten Digits}{28}{subsubsection.111}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Problem Description}{28}{subsection.112}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3.1}Classification}{28}{subsubsection.113}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3.2}Bidirectional Symbol Grounding}{29}{subsubsection.114}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Experiment Details}{29}{subsection.115}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4.1}Dataplumbing}{29}{subsubsection.116}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.1.1}Combining Datasets}{29}{paragraph.117}}
\newlabel{sec:UCU_mnist_comb}{{4.2.4.1.1}{29}{Combining Datasets}{paragraph.117}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.1.2}Merging Modalities}{29}{paragraph.118}}
\newlabel{eqn:concat}{{4.1}{30}{Merging Modalities}{equation.119}{}}
\newlabel{eqn:add}{{4.2}{30}{Merging Modalities}{equation.120}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4.2}Training Procedures}{30}{subsubsection.121}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.2.1}Bimodal}{30}{paragraph.122}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.2.2}Randomly Degraded}{30}{paragraph.123}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4.3}Testing Conditions}{31}{subsubsection.124}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.3.1}Bimodal}{31}{paragraph.125}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.3.2}Image Only}{31}{paragraph.126}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.3.3}MFCC Only}{31}{paragraph.127}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4.4}Network Description}{31}{subsubsection.128}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.4.1}Baseline Models}{31}{paragraph.129}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Image autoencoder and classifier. Layer 6c performs classification, whilst the branch starting at layer 6 regenerates the image.\relax }}{32}{table.caption.130}}
\newlabel{tab:MNIST_AE_description}{{4.2}{32}{Image autoencoder and classifier. Layer 6c performs classification, whilst the branch starting at layer 6 regenerates the image.\relax }{table.caption.130}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces MFCC autoencoder and classifier. Layer 7c performs classification, whilst the branch starting at layer 7 regenerates the MFCCs. The addition of reshape layers is to ensure the final shape of the regenerated MFCCs matches the target shape whilst the embedding shape matches that of the embedding of the image autoencoder.\relax }}{32}{table.caption.131}}
\newlabel{tab:UCU_AE_description}{{4.3}{32}{MFCC autoencoder and classifier. Layer 7c performs classification, whilst the branch starting at layer 7 regenerates the MFCCs. The addition of reshape layers is to ensure the final shape of the regenerated MFCCs matches the target shape whilst the embedding shape matches that of the embedding of the image autoencoder.\relax }{table.caption.131}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.4.4.2}Multimodal Autoencoder}{32}{paragraph.132}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Image and MFCC multimodal autoencoder. Layers marked i, m, im and c are image, MFCC, image and MFCC and classification respectively.\relax }}{33}{table.caption.133}}
\newlabel{tab:UCU_MNIST_MAE_description}{{4.4}{33}{Image and MFCC multimodal autoencoder. Layers marked i, m, im and c are image, MFCC, image and MFCC and classification respectively.\relax }{table.caption.133}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Results}{33}{subsection.134}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5.1}Classification Results}{33}{subsubsection.135}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits\relax }}{34}{table.caption.136}}
\newlabel{tab:mnist_ucu_master_res}{{4.5}{34}{Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits\relax }{table.caption.136}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the bimodal only testing condition.\relax }}{34}{table.caption.137}}
\newlabel{tab:mnist_ucu_bi_res}{{4.6}{34}{Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the bimodal only testing condition.\relax }{table.caption.137}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the image only testing condition.\relax }}{34}{table.caption.138}}
\newlabel{tab:mnist_ucu_im_res}{{4.7}{34}{Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the image only testing condition.\relax }{table.caption.138}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the MFCC only testing condition.\relax }}{35}{table.caption.139}}
\newlabel{tab:mnist_ucu_mfcc_res}{{4.8}{35}{Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the MFCC only testing condition.\relax }{table.caption.139}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces A selection of randomly sampled digits generated in different training and testing conditions for both \textit  {Add} and \textit  {Concat} merging methods.\relax }}{35}{figure.caption.141}}
\newlabel{fig:mnistDigits}{{4.2}{35}{A selection of randomly sampled digits generated in different training and testing conditions for both \textit {Add} and \textit {Concat} merging methods.\relax }{figure.caption.141}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5.2}Reconstruction Results}{35}{subsubsection.140}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}Discussion}{35}{subsection.143}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6.1}Discussion of Classification Results}{35}{subsubsection.144}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Two examples of the digit 5 being generated in different training and testing conditions for both \textit  {Add} and \textit  {Concat} merging methoids.\relax }}{36}{figure.caption.142}}
\newlabel{fig:5s}{{4.3}{36}{Two examples of the digit 5 being generated in different training and testing conditions for both \textit {Add} and \textit {Concat} merging methoids.\relax }{figure.caption.142}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6.2}Discussion of Reconstruction Results}{37}{subsubsection.145}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.6.2.1}Image reconstruction from MFCCs}{37}{paragraph.146}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.6.2.2}MFCC reconstruction from Images}{38}{paragraph.147}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.6.2.3}Effects of randomly degrading inputs}{39}{paragraph.148}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.6.2.4}Multiple generations of the same digit}{39}{paragraph.149}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Conclusion}{39}{section.150}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Magical Vectors and Where to Find Them}{41}{chapter.151}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter5}{{5}{41}{Magical Vectors and Where to Find Them}{chapter.151}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}ANN Latent space: the Final Frontier}{41}{section.152}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Vector Arithematic Explained}{42}{subsection.153}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Artifical Shapes Dataset}{42}{section.154}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}dataset description}{42}{subsection.155}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}problem description}{42}{subsection.156}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}network description}{42}{subsection.157}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}results}{42}{subsection.158}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.1}Image Generation}{42}{subsubsection.159}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.2}Multilabel classification}{42}{subsubsection.160}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4.3}Vector Arithematic}{42}{subsubsection.161}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}discussion}{42}{subsection.162}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Real Shapes Dataset}{42}{section.163}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}dataset description}{42}{subsection.164}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}problem description}{42}{subsection.165}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}network description}{42}{subsection.166}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}results}{42}{subsection.167}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.1}Image Generation}{42}{subsubsection.168}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.2}Multilabel classification}{42}{subsubsection.169}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.3}Vector Arithematic}{42}{subsubsection.170}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}discussion}{42}{subsection.171}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Transfer Learning: kick-starting the learning process}{43}{chapter.172}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter6}{{6}{43}{Transfer Learning: kick-starting the learning process}{chapter.172}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}What is transfer learning}{43}{section.173}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}randomly initialised networks}{43}{subsection.174}}
\newlabel{sec:random_init}{{6.1.1}{43}{randomly initialised networks}{subsection.174}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}A biological analogue}{43}{subsection.175}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}The importance of transfer learning}{43}{section.176}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}MultiSense 1 dataset}{43}{section.177}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}dataset description}{43}{subsection.178}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}problem description: image generation from raw speech audio}{43}{subsection.179}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}network description}{43}{subsection.180}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}results}{43}{subsection.181}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.5}discussion}{43}{subsection.182}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}What have we learnt and more importantly, what have our neural nets learnt?}{44}{chapter.183}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter7}{{7}{44}{What have we learnt and more importantly, what have our neural nets learnt?}{chapter.183}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Summary of important points}{44}{section.184}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Conclusion}{44}{section.185}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Future Work}{45}{chapter.186}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter8}{{8}{45}{Future Work}{chapter.186}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Where do we go now?}{45}{section.187}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}More Sensors}{45}{subsection.188}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Better Sensors}{45}{subsection.189}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Swarm Robots and the Cloud}{45}{subsection.190}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\vspace  {2em}}
\bibstyle{apalike}
\bibdata{Bibliography}
\bibcite{barsalou2008grounded}{{1}{2008}{{Barsalou}}{{}}}
\bibcite{hammami2010improved}{{2}{2010}{{Hammami and Bedda}}{{}}}
\bibcite{hammami2009tree}{{3}{2009}{{Hammami and Sellam}}{{}}}
\bibcite{kingma2014adam}{{4}{2014}{{Kingma and Ba}}{{}}}
\bibcite{lecun1998mnist}{{5}{1998}{{LeCun}}{{}}}
\bibcite{ma2009lip}{{6}{2009}{{Ma et~al.}}{{}}}
\bibcite{mcgurk1976hearing}{{7}{1976}{{McGurk and MacDonald}}{{}}}
\bibcite{ngiam2011multimodal}{{8}{2011}{{Ngiam et~al.}}{{}}}
\bibcite{rosenblatt1958perceptron}{{9}{1958}{{Rosenblatt}}{{}}}
\bibcite{samuel1997lexical}{{10}{1997}{{Samuel}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{46}{dummy.191}}
\newlabel{Bibliography}{{6}{46}{Swarm Robots and the Cloud}{dummy.191}{}}
\bibcite{senior2013empirical}{{11}{2013}{{Senior et~al.}}{{}}}
\bibcite{smith2008infants}{{12}{2008}{{Smith and Yu}}{{}}}
\bibcite{yurovsky2013statistical}{{13}{2013}{{Yurovsky et~al.}}{{}}}
\bibcite{zeiler2012adadelta}{{14}{2012}{{Zeiler}}{{}}}

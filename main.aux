\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Declaration of Authorship}{i}{dummy.1}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Abstract}{ii}{dummy.2}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iii}{dummy.3}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Contents}{iv}{dummy.4}}
\gdef \LT@i {\LT@entry 
    {1}{48.04353pt}\LT@entry 
    {1}{169.3712pt}}
\@writefile{toc}{\contentsline {chapter}{Abbreviations}{vi}{dummy.6}}
\citation{rosenblatt1958perceptron}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}A Primer on Artifical Neural Networks}{1}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter3}{{1}{1}{A Primer on Artifical Neural Networks}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{1}{section.10}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Perceptrons}{1}{section.11}}
\newlabel{sec:percep}{{1.2}{1}{Perceptrons}{section.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}What is a Perceptron}{1}{subsection.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces A perceptron with three binary inputs, $x_0, x_1, x_2$.\relax }}{2}{figure.caption.13}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:perceptron}{{1.1}{2}{A perceptron with three binary inputs, $x_0, x_1, x_2$.\relax }{figure.caption.13}{}}
\newlabel{eqn:percep}{{1.1}{2}{What is a Perceptron}{equation.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A multi-layer perceptron consisting of three perceptrons arranged in two layers, with three binary inputs, $x_0, x_1, x_2$.\relax }}{3}{figure.caption.16}}
\newlabel{fig:mlp}{{1.2}{3}{A multi-layer perceptron consisting of three perceptrons arranged in two layers, with three binary inputs, $x_0, x_1, x_2$.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Multi-Layer Perceptron}{3}{subsection.15}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Activation Functions}{3}{section.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Visualisation of the perceptron activation function.\relax }}{4}{figure.caption.18}}
\newlabel{fig:activation_percep}{{1.3}{4}{Visualisation of the perceptron activation function.\relax }{figure.caption.18}{}}
\newlabel{eqn:proport}{{1.2}{4}{Activation Functions}{equation.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Sigmoid Neurons}{4}{subsection.20}}
\newlabel{eqn:sig}{{1.3}{4}{Sigmoid Neurons}{equation.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Visualisation of the sigmoid activation function.\relax }}{5}{figure.caption.23}}
\newlabel{fig:activation_sigmoid}{{1.4}{5}{Visualisation of the sigmoid activation function.\relax }{figure.caption.23}{}}
\newlabel{eqn:z_act}{{1.4}{5}{Sigmoid Neurons}{equation.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1.1}Other activation functions}{5}{subsubsection.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Visualisation of the hyperbolic tangent activation function.\relax }}{6}{figure.caption.25}}
\newlabel{fig:activation_tanh}{{1.5}{6}{Visualisation of the hyperbolic tangent activation function.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Visualisation of the rectified linear unit activation function.\relax }}{6}{figure.caption.26}}
\newlabel{fig:activation_relu}{{1.6}{6}{Visualisation of the rectified linear unit activation function.\relax }{figure.caption.26}{}}
\citation{lecun1998mnist}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Learning Algorithms}{7}{section.28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Types of Training}{7}{subsection.30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Cost functions: How wrong am I?}{8}{subsection.31}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2.1}Mean Squared Error}{8}{subsubsection.32}}
\newlabel{eqn:mse}{{1.5}{8}{Mean Squared Error}{equation.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2.2}Cross-Entropy}{8}{subsubsection.34}}
\newlabel{eqn:xentrpy}{{1.6}{9}{Cross-Entropy}{equation.35}{}}
\newlabel{eqn:xentrpy_eg}{{1.7}{9}{Cross-Entropy}{equation.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2.3}Kullback-Leibler Divergence}{9}{subsubsection.37}}
\newlabel{eqn:kld}{{1.8}{9}{Kullback-Leibler Divergence}{equation.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces The cost landscape of a bivariate function\relax }}{10}{figure.caption.40}}
\newlabel{fig:costscape}{{1.7}{10}{The cost landscape of a bivariate function\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Gradient Descent}{10}{subsection.39}}
\newlabel{eqn:cost_bivar}{{1.9}{11}{Gradient Descent}{equation.41}{}}
\newlabel{eqn:delta_C}{{1.10}{11}{Gradient Descent}{equation.42}{}}
\newlabel{eqn:nabla_c}{{1.11}{11}{Gradient Descent}{equation.43}{}}
\newlabel{eqn:delta_c_sub}{{1.12}{11}{Gradient Descent}{equation.44}{}}
\newlabel{eqn:delta_w_eta}{{1.13}{11}{Gradient Descent}{equation.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Backpropagation}{12}{subsection.47}}
\newlabel{eqn:BP1}{{1.14}{12}{Backpropagation}{equation.48}{}}
\newlabel{eqn:BP2}{{1.15}{12}{Backpropagation}{equation.49}{}}
\newlabel{eqn:hada}{{1.16}{12}{}{equation.51}{}}
\newlabel{eqn:BP3}{{1.17}{13}{Backpropagation}{equation.52}{}}
\newlabel{eqn:BP4}{{1.18}{13}{Backpropagation}{equation.53}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}Extensions and Improvements}{13}{subsection.54}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.5.1}Learning Rate Schedule}{13}{subsubsection.55}}
\newlabel{sec:lr_sch}{{1.4.5.1}{13}{Learning Rate Schedule}{subsubsection.55}{}}
\citation{kingma2014adam}
\citation{zeiler2012adadelta}
\citation{senior2013empirical}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Visualisation of cost minimisation in two dimensions for different learning rate schedules. Blue: decreaseing learning rate, Red: large fixed learning rate.\relax }}{14}{figure.caption.56}}
\newlabel{fig:lr_schedule}{{1.8}{14}{Visualisation of cost minimisation in two dimensions for different learning rate schedules. Blue: decreaseing learning rate, Red: large fixed learning rate.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Visualisation of the cost (black), its first derivative (blue) and second derivative (red).\relax }}{15}{figure.caption.57}}
\newlabel{fig:2ndordr}{{1.9}{15}{Visualisation of the cost (black), its first derivative (blue) and second derivative (red).\relax }{figure.caption.57}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Convolutional Neural Networks}{16}{section.58}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}What is Convolution?}{16}{subsection.59}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1.1}Kernels}{16}{subsubsection.60}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1.2}Strides}{16}{subsubsection.61}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1.3}Dilations}{16}{subsubsection.62}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Transposed Convolutions}{16}{subsection.63}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Recurrent Neural Networks}{16}{section.64}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Vanilla RNN}{16}{subsection.65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.2}Gated RNN}{16}{subsection.66}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Summary}{16}{section.67}}
\citation{barsalou2008grounded}
\citation{mcgurk1976hearing}
\citation{ma2009lip}
\citation{ma2009lip,samuel1997lexical}
\citation{ngiam2011multimodal}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Sensory Redundancy: Are two heads better than one?}{17}{chapter.68}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter4}{{2}{17}{Sensory Redundancy: Are two heads better than one?}{chapter.68}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Why have one sensor when two are better?}{17}{section.69}}
\citation{hammami2009tree,hammami2010improved}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Generating images from natural language}{18}{section.70}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Aims}{18}{subsection.71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}UCU Arabic Spoken Digits and MNIST}{18}{subsection.72}}
\newlabel{sec:UCU}{{2.2.2}{18}{UCU Arabic Spoken Digits and MNIST}{subsection.72}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.1}UCU Arabic Spoken Digits}{18}{subsubsection.73}}
\citation{lecun1998mnist}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Mean number of samples for each digit in the UCU Arabic Spoken Digits Dataset. Red bars show the standard devaition in length for each each digit.\relax }}{19}{figure.caption.75}}
\newlabel{fig:ucu_dig_length}{{2.1}{19}{Mean number of samples for each digit in the UCU Arabic Spoken Digits Dataset. Red bars show the standard devaition in length for each each digit.\relax }{figure.caption.75}{}}
\citation{barsalou2008grounded}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Mean length and standard deviation of digits in the UCU dataset.\relax }}{20}{table.caption.76}}
\newlabel{tab:UCU_sampLen}{{2.1}{20}{Mean length and standard deviation of digits in the UCU dataset.\relax }{table.caption.76}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.2}MNIST Handwritten Digits}{20}{subsubsection.77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Problem Description}{20}{subsection.78}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.1}Classification}{20}{subsubsection.79}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.2}Bidirectional Symbol Grounding}{21}{subsubsection.80}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Experiment Details}{21}{subsection.81}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.1}Dataplumbing}{21}{subsubsection.82}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.1.1}Combining Datasets}{21}{paragraph.83}}
\newlabel{sec:UCU_mnist_comb}{{2.2.4.1.1}{21}{Combining Datasets}{paragraph.83}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.1.2}Merging Modalities}{21}{paragraph.84}}
\newlabel{eqn:concat}{{2.1}{22}{Merging Modalities}{equation.85}{}}
\newlabel{eqn:add}{{2.2}{22}{Merging Modalities}{equation.86}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.2}Training Procedures}{22}{subsubsection.87}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.2.1}Bimodal}{22}{paragraph.88}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.2.2}Randomly Degraded}{22}{paragraph.89}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.3}Testing Conditions}{23}{subsubsection.90}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.3.1}Bimodal}{23}{paragraph.91}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.3.2}Image Only}{23}{paragraph.92}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.3.3}MFCC Only}{23}{paragraph.93}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.4}Network Description}{23}{subsubsection.94}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.4.1}Baseline Models}{23}{paragraph.95}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Image autoencoder and classifier. Layer 6c performs classification, whilst the branch starting at layer 6 regenerates the image.\relax }}{24}{table.caption.96}}
\newlabel{tab:MNIST_AE_description}{{2.2}{24}{Image autoencoder and classifier. Layer 6c performs classification, whilst the branch starting at layer 6 regenerates the image.\relax }{table.caption.96}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces MFCC autoencoder and classifier. Layer 7c performs classification, whilst the branch starting at layer 7 regenerates the MFCCs. The addition of reshape layers is to ensure the final shape of the regenerated MFCCs matches the target shape whilst the embedding shape matches that of the embedding of the image autoencoder.\relax }}{24}{table.caption.97}}
\newlabel{tab:UCU_AE_description}{{2.3}{24}{MFCC autoencoder and classifier. Layer 7c performs classification, whilst the branch starting at layer 7 regenerates the MFCCs. The addition of reshape layers is to ensure the final shape of the regenerated MFCCs matches the target shape whilst the embedding shape matches that of the embedding of the image autoencoder.\relax }{table.caption.97}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.4.4.2}Multimodal Autoencoder}{24}{paragraph.98}}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Image and MFCC multimodal autoencoder. Layers marked i, m, im and c are image, MFCC, image and MFCC and classification respectively.\relax }}{25}{table.caption.99}}
\newlabel{tab:UCU_MNIST_MAE_description}{{2.4}{25}{Image and MFCC multimodal autoencoder. Layers marked i, m, im and c are image, MFCC, image and MFCC and classification respectively.\relax }{table.caption.99}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Results}{25}{subsection.100}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.1}Classification Results}{25}{subsubsection.101}}
\@writefile{lot}{\contentsline {table}{\numberline {2.5}{\ignorespaces Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits\relax }}{26}{table.caption.102}}
\newlabel{tab:mnist_ucu_master_res}{{2.5}{26}{Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits\relax }{table.caption.102}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.6}{\ignorespaces Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the bimodal only testing condition.\relax }}{26}{table.caption.103}}
\newlabel{tab:mnist_ucu_bi_res}{{2.6}{26}{Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the bimodal only testing condition.\relax }{table.caption.103}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.7}{\ignorespaces Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the image only testing condition.\relax }}{26}{table.caption.104}}
\newlabel{tab:mnist_ucu_im_res}{{2.7}{26}{Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the image only testing condition.\relax }{table.caption.104}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.8}{\ignorespaces Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the MFCC only testing condition.\relax }}{27}{table.caption.105}}
\newlabel{tab:mnist_ucu_mfcc_res}{{2.8}{27}{Results from the combined MNIST Handwritten Digits and UCU Arabic Spoken Digits for the MFCC only testing condition.\relax }{table.caption.105}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.2}Reconstruction Results}{27}{subsubsection.106}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A selection of randomly sampled digits generated in different training and testing conditions for both \textit  {Add} and \textit  {Concat} merging methods.\relax }}{27}{figure.caption.107}}
\newlabel{fig:mnistDigits}{{2.2}{27}{A selection of randomly sampled digits generated in different training and testing conditions for both \textit {Add} and \textit {Concat} merging methods.\relax }{figure.caption.107}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Discussion}{27}{subsection.109}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.1}Discussion of Classification Results}{27}{subsubsection.110}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Two examples of the digit 5 being generated in different training and testing conditions for both \textit  {Add} and \textit  {Concat} merging methoids.\relax }}{28}{figure.caption.108}}
\newlabel{fig:5s}{{2.3}{28}{Two examples of the digit 5 being generated in different training and testing conditions for both \textit {Add} and \textit {Concat} merging methoids.\relax }{figure.caption.108}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.2}Discussion of Reconstruction Results}{29}{subsubsection.111}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.6.2.1}Image reconstruction from MFCCs}{29}{paragraph.112}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.6.2.2}MFCC reconstruction from Images}{30}{paragraph.113}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.6.2.3}Effects of randomly degrading inputs}{31}{paragraph.114}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.2.6.2.4}Multiple generations of the same digit}{31}{paragraph.115}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Conclusion}{31}{section.116}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\vspace  {2em}}
\bibstyle{apalike}
\bibdata{Bibliography}
\bibcite{barsalou2008grounded}{{1}{2008}{{Barsalou}}{{}}}
\bibcite{hammami2010improved}{{2}{2010}{{Hammami and Bedda}}{{}}}
\bibcite{hammami2009tree}{{3}{2009}{{Hammami and Sellam}}{{}}}
\bibcite{kingma2014adam}{{4}{2014}{{Kingma and Ba}}{{}}}
\bibcite{lecun1998mnist}{{5}{1998}{{LeCun}}{{}}}
\bibcite{ma2009lip}{{6}{2009}{{Ma et~al.}}{{}}}
\bibcite{mcgurk1976hearing}{{7}{1976}{{McGurk and MacDonald}}{{}}}
\bibcite{ngiam2011multimodal}{{8}{2011}{{Ngiam et~al.}}{{}}}
\bibcite{rosenblatt1958perceptron}{{9}{1958}{{Rosenblatt}}{{}}}
\bibcite{samuel1997lexical}{{10}{1997}{{Samuel}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{33}{dummy.117}}
\newlabel{Bibliography}{{6}{33}{Conclusion}{dummy.117}{}}
\bibcite{senior2013empirical}{{11}{2013}{{Senior et~al.}}{{}}}
\bibcite{zeiler2012adadelta}{{12}{2012}{{Zeiler}}{{}}}

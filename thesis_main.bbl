\begin{thebibliography}{10}

\bibitem{smith2008infants}
L.~Smith and C.~Yu,
{\em Infants rapidly learn word-referent mappings via cross-situational
  statistics,}
Cognition {\bf 106} (2008) 1558.

\bibitem{yurovsky2013statistical}
D.~Yurovsky, L.~B.~Smith, and C.~Yu,
{\em Statistical word learning at scale: The baby's view is better,}
Developmental science {\bf 16} (2013) 959.

\bibitem{rosenblatt1958perceptron}
F.~Rosenblatt,
{\em The perceptron: a probabilistic model for information storage and
  organization in the brain.,}
Psychological review {\bf 65} (1958) 386.

\bibitem{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E.~Hinton.
\newblock {\em Imagenet classification with deep convolutional neural
  networks,} .
\newblock In {\em Advances in neural information processing systems} 10972012.

\bibitem{ma2004facial}
L.~Ma and K.~Khorasani,
{\em Facial expression recognition using constructive feedforward neural
  networks,}
IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics) {\bf
  34} (2004) 1588.

\bibitem{levi2015emotion}
G.~Levi and T.~Hassner.
\newblock {\em Emotion recognition in the wild via convolutional neural
  networks and mapped binary patterns,} .
\newblock In {\em Proceedings of the 2015 ACM on international conference on
  multimodal interaction} 503. ACM2015.

\bibitem{kussul2017deep}
N.~Kussul, M.~Lavreniuk, S.~Skakun, and A.~Shelestov,
{\em Deep learning classification of land cover and crop types using remote
  sensing data,}
IEEE Geoscience and Remote Sensing Letters {\bf 14} (2017) 778.

\bibitem{qi2017pointnet}
C.~R.~Qi, H.~Su, K.~Mo, and L.~J.~Guibas.
\newblock {\em Pointnet: Deep learning on point sets for 3d classification and
  segmentation,} .
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition} 6522017.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman,
{\em Very deep convolutional networks for large-scale image recognition,}
arXiv preprint arXiv:1409.1556(2014).

\bibitem{springenberg2014striving}
J.~T.~Springenberg, A.~Dosovitskiy, T.~Brox, and M.~Riedmiller,
{\em Striving for simplicity: The all convolutional net,}
arXiv preprint arXiv:1412.6806(2014).

\bibitem{srivastava2014dropout}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov,
{\em Dropout: a simple way to prevent neural networks from overfitting,}
The journal of machine learning research {\bf 15} (2014) 1929.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock {\em Deep residual learning for image recognition,} .
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition} 7702016.

\bibitem{hochreiter1998vanishing}
S.~Hochreiter,
{\em The vanishing gradient problem during learning recurrent neural nets and
  problem solutions,}
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems
  {\bf 6} (1998) 107.

\bibitem{szegedy2015going}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich.
\newblock {\em Going deeper with convolutions,} .
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}~12015.

\bibitem{szegedy2016rethinking}
C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna.
\newblock {\em Rethinking the inception architecture for computer vision,} .
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition} 28182016.

\bibitem{szegedy2017inception}
C.~Szegedy, S.~Ioffe, V.~Vanhoucke, and A.~A.~Alemi.
\newblock {\em Inception-v4, inception-resnet and the impact of residual
  connections on learning,} .
\newblock In {\em Thirty-First AAAI Conference on Artificial Intelligence}2017.

\bibitem{vinyals2019alphastar}
O.~Vinyals, I.~Babuschkin, J.~Chung, M.~Mathieu, M.~Jaderberg, W.~M.~Czarnecki,
  A.~Dudzik, A.~Huang, P.~Georgiev, R.~Powell, and ~others,
{\em AlphaStar: Mastering the real-time strategy game StarCraft II,}
DeepMind Blog(2019).

\bibitem{lecun1998mnist}
Y.~LeCun,
{\em The MNIST database of handwritten digits,}
http://yann. lecun. com/exdb/mnist/(1998).

\bibitem{kingma2014adam}
D.~P.~Kingma and J.~Ba,
{\em Adam: A method for stochastic optimization,}
arXiv preprint arXiv:1412.6980(2014).

\bibitem{zeiler2012adadelta}
M.~D.~Zeiler,
{\em ADADELTA: an adaptive learning rate method,}
arXiv preprint arXiv:1212.5701(2012).

\bibitem{senior2013empirical}
A.~Senior, G.~Heigold, K.~Yang, and ~others.
\newblock {\em An empirical study of learning rates in deep neural networks for
  speech recognition,} .
\newblock In {\em 2013 IEEE international conference on acoustics, speech and
  signal processing} 6724. IEEE2013.

\bibitem{dumoulin2016guide}
V.~Dumoulin and F.~Visin,
{\em A guide to convolution arithmetic for deep learning,}
arXiv preprint arXiv:1603.07285(2016).

\bibitem{radford2015unsupervised}
A.~Radford, L.~Metz, and S.~Chintala,
{\em Unsupervised representation learning with deep convolutional generative
  adversarial networks,}
arXiv preprint arXiv:1511.06434(2015).

\bibitem{barsalou2008grounded}
L.~W.~Barsalou,
{\em Grounded cognition,}
Annu. Rev. Psychol. {\bf 59} (2008) 617.

\bibitem{mcgurk1976hearing}
H.~McGurk and J.~MacDonald,
{\em Hearing lips and seeing voices,}
Nature {\bf 264} (1976) 746.

\bibitem{ma2009lip}
W.~J.~Ma, X.~Zhou, L.~A.~Ross, J.~J.~Foxe, and L.~C.~Parra,
{\em Lip-reading aids word recognition most in moderate noise: a Bayesian
  explanation using high-dimensional feature space,}
PLoS One {\bf 4} (2009) e4638.

\bibitem{samuel1997lexical}
A.~G.~Samuel,
{\em Lexical activation produces potent phonemic percepts,}
Cognitive psychology {\bf 32} (1997)~97.

\bibitem{ngiam2011multimodal}
J.~Ngiam, A.~Khosla, M.~Kim, J.~Nam, H.~Lee, and A.~Y.~Ng.
\newblock {\em Multimodal deep learning,} .
\newblock In {\em Proceedings of the 28th international conference on machine
  learning (ICML-11)} 6892011.

\bibitem{hammami2009tree}
N.~Hammami and M.~Sellam.
\newblock {\em Tree distribution classifier for automatic spoken arabic digit
  recognition,} .
\newblock In {\em 2009 International Conference for Internet Technology and
  Secured Transactions,(ICITST)}~1. IEEE2009.

\bibitem{hammami2010improved}
N.~Hammami and M.~Bedda.
\newblock {\em Improved tree model for arabic speech recognition,} .
\newblock In {\em 2010 3rd International Conference on Computer Science and
  Information Technology}volume~5 521. IEEE2010.

\bibitem{mikolov2013distributed}
T.~Mikolov, I.~Sutskever, K.~Chen, G.~S.~Corrado, and J.~Dean.
\newblock {\em Distributed representations of words and phrases and their
  compositionality,} .
\newblock In {\em Advances in neural information processing systems} 31112013.

\bibitem{mikolov2013efficient}
T.~Mikolov, K.~Chen, G.~Corrado, and J.~Dean,
{\em Efficient estimation of word representations in vector space,}
arXiv preprint arXiv:1301.3781(2013).

\bibitem{schillingmann2009towards}
L.~Schillingmann, B.~Wrede, and K.~Rohlfing.
\newblock {\em Towards a computational model of acoustic packaging,} .
\newblock In {\em Development and Learning, 2009. ICDL 2009. IEEE 8th
  International Conference on}~1. IEEE2009.

\bibitem{schillingmann2009computational}
L.~Schillingmann, B.~Wrede, and K.~J.~Rohlfing,
{\em A computational model of acoustic packaging,}
IEEE Transactions on Autonomous Mental Development {\bf 1} (2009) 226.

\bibitem{keller2016analysis}
I.~Keller and K.~S.~Lohan.
\newblock {\em Analysis of illumination robustness in long-term object
  learning,} .
\newblock In {\em 2016 25th IEEE International Symposium on Robot and Human
  Interactive Communication (RO-MAN)} 240. IEEE2016.

\bibitem{keller}
I.~Keller and K.~S.~Lohan,
{\em {On the Illumination Influence for Object Learning on Robot Companions},}
Frontiers in Robotics and AI,(in press)(2019)~1.

\end{thebibliography}
